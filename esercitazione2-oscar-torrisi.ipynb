{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Esercitazione 2 - Regressione Lineare**","metadata":{}},{"cell_type":"markdown","source":"## Boston Housing dataset","metadata":{}},{"cell_type":"markdown","source":"Questo dataset contiene informazioni raccolte dal U.S. Census Service riguardanti le abitazioni nell'area di Boston, Massachusetts. È stato ottenuto dall'archivio StatLib (http://lib.stat.cmu.edu/datasets/boston) ed è stato ampiamente utilizzato in letteratura per fare benchmark di algoritmi. \n\nIl dataset contiene informazioni su 506 case, divise in 14 variabili.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.563302Z","iopub.execute_input":"2025-04-01T08:48:08.563748Z","iopub.status.idle":"2025-04-01T08:48:08.569023Z","shell.execute_reply.started":"2025-04-01T08:48:08.563712Z","shell.execute_reply":"2025-04-01T08:48:08.567774Z"},"trusted":true},"outputs":[],"execution_count":132},{"cell_type":"code","source":"import pandas as pd \nfrom sklearn.utils import shuffle\nfrom pandas import read_csv\n\nfrom sklearn.datasets import fetch_openml\nimport pandas as pd\n\n# Scarica il Boston Housing Dataset da OpenML\nboston = fetch_openml(name=\"Boston\", version=1, as_frame=True)\n\n# Estrai i dati (features) e il target (valore mediano delle abitazioni)\nX = boston.data\ny = boston.target\n\nX, y = shuffle(X, y, random_state=0)\nprint(f\"Features shape: {X.shape}, targets shape:  {y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.570503Z","iopub.execute_input":"2025-04-01T08:48:08.570941Z","iopub.status.idle":"2025-04-01T08:48:08.616530Z","shell.execute_reply.started":"2025-04-01T08:48:08.570896Z","shell.execute_reply":"2025-04-01T08:48:08.615203Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Features shape: (506, 13), targets shape:  (506,)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n  warn(\n","output_type":"stream"}],"execution_count":133},{"cell_type":"markdown","source":"## `np.c_` in NumPy\n\nL'oggetto `np.c_` in NumPy è una **scorciatoia** per concatenare array lungo il secondo asse (cioè, le colonne).\n\n## Utilizzo\n```python\nnp.c_[array1, array2, ...]\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Generate two random 2x3 matrices\nmatrice1 = np.random.rand(2, 3)\nmatrice2 = np.random.rand(2, 3)\n\n# Concatenate the matrices along columns\nrisultato = np.c_[matrice1, matrice2]\n\nprint(\"Matrice 1:\",matrice1.shape)\n\nprint(\"\\nMatrice 2:\",matrice2.shape)\n\nprint(\"\\nMatrice concatenata:\",risultato.shape)","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.618899Z","iopub.execute_input":"2025-04-01T08:48:08.619298Z","iopub.status.idle":"2025-04-01T08:48:08.627758Z","shell.execute_reply.started":"2025-04-01T08:48:08.619267Z","shell.execute_reply":"2025-04-01T08:48:08.626281Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Matrice 1: (2, 3)\n\nMatrice 2: (2, 3)\n\nMatrice concatenata: (2, 6)\n","output_type":"stream"}],"execution_count":134},{"cell_type":"markdown","source":"**Divisione del dataset**\n\nIl primo passaggio è quello di dividere i dati in train set, validation set e test set. Utilizza il 60% dei dati per il training set, il 20% per il validation e il restante 20% per il test set. Considerato che il nostro dataset possiede 506 osservazioni mi aspetto che:\n\n- Il **training set** avrà 303 osservazioni.\n- Il **validation set** avrà 101 osservazioni.\n- Il **test set** avrà 101 osservazioni.\n\nIn reatà il test set avrà 102 osservazioni per via delle approssimazioni.\n\n","metadata":{}},{"cell_type":"code","source":"# Divisione del dataset\n\ntrain_porzione = 0.6  \nval_porzione = 0.2  \ntest_porzione = 0.2\n\nnum_campione, dimensione =X.shape\n\nnum_train=int(num_campione*train_porzione)\nnum_validation=int(num_campione*val_porzione)\nX_train=X[:num_train]\ny_train=y[:num_train]\nX_validation=X[num_train:num_train+num_validation]\ny_validation=y[num_train:num_train+num_validation]\nX_test=X[num_train+num_validation:]\ny_test=y[num_train+num_validation:]\n\nprint(X_train.shape)\nprint(X_validation.shape)\nprint(X_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.629401Z","iopub.execute_input":"2025-04-01T08:48:08.629784Z","iopub.status.idle":"2025-04-01T08:48:08.651979Z","shell.execute_reply.started":"2025-04-01T08:48:08.629738Z","shell.execute_reply":"2025-04-01T08:48:08.650881Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(303, 13)\n(101, 13)\n(102, 13)\n","output_type":"stream"}],"execution_count":135},{"cell_type":"markdown","source":"### **Esercizio 1: Costruisci una Pipeline di Regressione Lineare Standardizzata**\n\n**Step 1:** Standardizza i dataset di addestramento, validazione e test. Usa `StandardScaler` di scikit-learn.  \n\n**Step 2:** Aggiungi una feature costante (bias) ai dati concatenando una colonna di uno ad ogni dataset.  \n\n**Step 3:** Implementa la soluzione in forma chiusa per l'addestramento di un modello di regressione lineare. \n \n**Step 4:** Valuta il modello calcolando il Mean Absolute Error (MAE) sui dataset di addestramento, validazione e test.\n","metadata":{}},{"cell_type":"markdown","source":"### **Guida**\n\n1. **StandardScaler**:\n   - Utilizza `StandardScaler` da `sklearn.preprocessing` per standardizzare i dati.\n   - Il metodo `fit_transform` calcola la media e la varianza dei dati di addestramento e li scala di conseguenza.\n   - Utilizza `transform` per standardizzare i dati di validazione e test utilizzando gli stessi parametri. Utilizziamo il metodo `transform` perchè non calcola i parametri di scaling (media e std). In questo modo ci assicuriamo che i dati di training e quelli di validation e test vengano scalati in modo uguale. Se usassimo `fit_transform` avremmo degli scaling diversi.\n\n2. **Aggiunta di una Caratteristica Costante**:\n   - Utilizza `np.c_` per concatenare una colonna di uno alle matrici delle caratteristiche. Questo è importante per includere il termine di intercetta nella regressione lineare.\n\n3. **Soluzione in Forma Chiusa per la Regressione Lineare**:\n   - La soluzione in forma chiusa è:\n\n     $$\\theta = (X^T X)^{-1} X^T y$$\n\n   - Per calcolare la trasposta di una matrice possiamo utilizzare l' attributo `.T` di cui ogni array è dotato.\n\n   - Utilizza `np.linalg.inv` di NumPy per l'inversione della matrice e l'operatore `@` per la moltiplicazione matriciale.\n  \n   - Puoi utilizzare l'operatore @ per eseguire l'operazione np.dot (`A @ B` è equivalente a `np.dot(A, B)`).\n\n4. **Mean Absolute Error (MAE)**:\n   - L'MAE si calcola come:\n\n     $$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|$$\n\n   - Utilizza `np.mean` e `np.abs` per calcolarlo.\n","metadata":{}},{"cell_type":"code","source":"# Step 1 - Normalizzazione dei dati. Dobbiamo normalizzare le features \n# sia del training set, validation set e test set.\n\n# Utilizziamo il metodo .fit_transform() dello scaler per normalizzare le feature di training.\n\n# Per normalizzare le feature di validation e test utilizziamo il metodo .transform()\n\nfrom sklearn.preprocessing import StandardScaler \nss = StandardScaler()\n# svolgimento...\nX_train_norm=ss.fit_transform(X_train)\n#print(X_train_norm)\nX_validation_norm=ss.transform(X_validation)\nX_test_norm=ss.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.653207Z","iopub.execute_input":"2025-04-01T08:48:08.653628Z","iopub.status.idle":"2025-04-01T08:48:08.684214Z","shell.execute_reply.started":"2025-04-01T08:48:08.653577Z","shell.execute_reply":"2025-04-01T08:48:08.683197Z"},"trusted":true},"outputs":[],"execution_count":136},{"cell_type":"code","source":"# Step 2 - Aggiunta di una feature costante\n\n# creiamo un vettore di 1 da aggiungere come feature costante. \n# ATTENZIONE: questo vettore deve avere le stesse righe del set a cui viene aggiunto. \n# Uno uguale per tutti non va bene\n\n# svolgimento...\nvettore_di_uni_tr = np.ones((X_train_norm.shape[0], 1))\nX_train_cost = np.c_[vettore_di_uni_tr,X_train_norm, ]\n\nvettore_di_uni_val = np.ones((X_validation_norm.shape[0], 1))\nX_validation_cost = np.c_[vettore_di_uni_val,X_validation_norm]\n\nvettore_di_uni_te = np.ones((X_test_norm.shape[0], 1))\nX_test_cost = np.c_[vettore_di_uni_te,X_test_norm]","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.685356Z","iopub.execute_input":"2025-04-01T08:48:08.685843Z","iopub.status.idle":"2025-04-01T08:48:08.717053Z","shell.execute_reply.started":"2025-04-01T08:48:08.685800Z","shell.execute_reply":"2025-04-01T08:48:08.715568Z"},"trusted":true},"outputs":[],"execution_count":137},{"cell_type":"code","source":"# Step 3 - Applichiamo la formula matematica della regressione lineare\n\n# ATTENZIONE: stiamo per effettuare operazioni tra matrici e vettori, \n# non si tratta di una semplice formula matematica, stiamo attenti a quali operatori utilizzare e quanto\n\n# svolgimento...\nparametri=np.linalg.inv(X_train_cost.T@X_train_cost)@X_train_cost.T@y_train\n","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.720861Z","iopub.execute_input":"2025-04-01T08:48:08.721269Z","iopub.status.idle":"2025-04-01T08:48:08.740723Z","shell.execute_reply.started":"2025-04-01T08:48:08.721226Z","shell.execute_reply":"2025-04-01T08:48:08.739585Z"},"trusted":true},"outputs":[],"execution_count":138},{"cell_type":"code","source":"# Step 4 - Calcolo MAE\n\n# Calcoliamo l'errore medio assoluto (MAE) per il training set, validation set e test set.\n# Utlizziamo la formula specificata nella guida.\n\n# svolgimento...\n\ny_predetti_train=X_train_cost@parametri\nMAE=np.mean(np.abs(y_train - y_predetti_train))\n#print(y_predetti)\nprint(MAE)\n\n\ny_predetti_val=X_validation_cost@parametri\nMAE=np.mean(np.abs(y_validation - y_predetti_val))\nprint(MAE)\n\ny_predetti_test=X_test_cost@parametri\nMAE=np.mean(np.abs(y_test - y_predetti_test))\nprint(MAE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T08:48:08.742112Z","iopub.execute_input":"2025-04-01T08:48:08.742492Z","iopub.status.idle":"2025-04-01T08:48:08.768307Z","shell.execute_reply.started":"2025-04-01T08:48:08.742462Z","shell.execute_reply":"2025-04-01T08:48:08.767189Z"}},"outputs":[{"name":"stdout","text":"3.2496837441036983\n3.5977784744283965\n3.0197366706166866\n","output_type":"stream"}],"execution_count":139},{"cell_type":"markdown","source":"### **Esercizio: Costruisci una pipeline di Regressione Lineare Standardizzata utilizzando `scikit-learn`** \n\n**Step 1 & 2:** Step 1 e 2 sono uguali a quanto fatto prima.\n\n**Step 3:** Utilizza `LinearRegression()` di scikit-learn per addestrare un modello di regressione lineare.  \n\n**Step 4:** Valuta il modello calcolando il Mean Absolute Error (MAE) sui dataset di addestramento, validazione e test, utilizzando `mean_absolute_error()` da `sklearn.metrics`.\n","metadata":{}},{"cell_type":"markdown","source":"## `LinearRegression` da Scikit-Learn\n\nLa classe `LinearRegression` in Scikit-Learn viene utilizzata per eseguire la **regressione lineare**, adattando un modello lineare al dataset.\n\n## **Sintassi**\n```python\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\n# Dati di esempio\nX = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\ny = np.array([10, 15, 20, 25])\n\n# Adatta il modello ai dati\nmodel.fit(X, y)\n\n# Predici nuovi valori\nX_new = np.array([[3, 5], [5, 9]])\npredictions = model.predict(X_new)\n","metadata":{}},{"cell_type":"markdown","source":"## `mean_absolute_error` da Scikit-Learn\n\nLa funzione `mean_absolute_error` calcola l'**errore assoluto medio** (MAE) tra i valori target reali e quelli predetti.\n\n## **Sintassi**\n```python\nsklearn.metrics.mean_absolute_error(y_true, y_pred)\n","metadata":{}},{"cell_type":"markdown","source":"### **Guida**\n\n1. **Istanziare e allenare un modello di regressione lineare**:\n    \n    - Istanziamo una classe `LinearRegression` per creare il modello.\n    - Utilizziamo il metodo `.fit()` per allenare il modello con i dati di training.\n\n2. **Effettuare predizioni con il modello**:\n\n    - Utiliziamo il metodo `.predict()` del modello per effettuare le predizioni. Effettuiamo le predizioni per tutti i set che abbiamo (train, validation e test).\n\n3. **Calcolo della MAE**: \n\n    - Calcolare MAE su tutti i set utilizzando la funzione `mean_abslute_error`\n","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.769610Z","iopub.execute_input":"2025-04-01T08:48:08.770077Z","iopub.status.idle":"2025-04-01T08:48:08.791069Z","shell.execute_reply.started":"2025-04-01T08:48:08.769994Z","shell.execute_reply":"2025-04-01T08:48:08.789715Z"},"trusted":true},"outputs":[],"execution_count":140},{"cell_type":"code","source":"# Step 1 - Istanziare e allenare il modello di regressione lineare.\n\n# svolgimento...\nmodel = LinearRegression()\nmodel.fit(X_train_cost, y_train)\n\n","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.792089Z","iopub.execute_input":"2025-04-01T08:48:08.792381Z","iopub.status.idle":"2025-04-01T08:48:08.828519Z","shell.execute_reply.started":"2025-04-01T08:48:08.792356Z","shell.execute_reply":"2025-04-01T08:48:08.827297Z"},"trusted":true},"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"LinearRegression()","text/html":"<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":141},{"cell_type":"code","source":"# Step 2 - Effettuare predizioni\n\n# svolgimento...\n\npredictions = model.predict(X_validation_cost)\nprint(predictions)\n\npredictions2 = model.predict(X_test_cost)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T08:48:08.829607Z","iopub.execute_input":"2025-04-01T08:48:08.830053Z","iopub.status.idle":"2025-04-01T08:48:08.849595Z","shell.execute_reply.started":"2025-04-01T08:48:08.829992Z","shell.execute_reply":"2025-04-01T08:48:08.848297Z"}},"outputs":[{"name":"stdout","text":"[17.85368076 24.35599708 20.09756296 27.15300859 -2.62930152 20.46393688\n 35.41152823 35.71985444 25.28583845 27.76744086 22.31663672 20.83612712\n 14.39487678 18.37848826 21.05925004 27.61394996 19.92847733  8.84392688\n 16.47054387 32.72927669 34.19962182 18.3705175  18.59070139 23.80887644\n 11.0335417  21.8326655  23.2312444  17.55263426 18.8738146  20.84864232\n 27.20681312 24.89091927 37.42978939 16.05716997 29.03884418 26.30846749\n 22.63754586 38.53668733 20.59484962 23.15705962 22.86416926 17.96551612\n 21.25651564 33.68990671 24.28505587 19.09328489 33.8581486  22.97004967\n 28.63666225 32.89489853 35.76930533 21.53040026 26.01959657 22.45363322\n 30.70819235 22.54147534 19.98590793 22.58404746 28.30329079 22.63000898\n 21.61810222 16.25968155 18.71149195 18.47841886 18.32562191 16.69093976\n 31.06703735 24.6796598  19.19742258 19.98737464 32.64480151 14.46286601\n 24.94206032 18.66492084 29.51605961 28.68792204 23.54212041 21.11939515\n 34.9808177  22.66671139 33.53856716 20.58693402 31.13307994 31.42460552\n 37.28631225 26.95723773 23.06611971 28.4196831  17.65676313 25.74999234\n 21.01229621 31.01186463  9.78904588 30.17085245  6.84055418 16.71369146\n 18.16057124 35.04152448 32.26570926  9.43467925 11.95664063]\n","output_type":"stream"}],"execution_count":142},{"cell_type":"code","source":"# Step 3 - Calcolo MAE\n\n# svolgimento...\n\nprint(mean_absolute_error(y_validation, predictions))\nprint(mean_absolute_error(y_test, predictions2))","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.850565Z","iopub.execute_input":"2025-04-01T08:48:08.850923Z","iopub.status.idle":"2025-04-01T08:48:08.876159Z","shell.execute_reply.started":"2025-04-01T08:48:08.850894Z","shell.execute_reply":"2025-04-01T08:48:08.874922Z"},"trusted":true},"outputs":[{"name":"stdout","text":"3.5977784744283983\n3.019736670616686\n","output_type":"stream"}],"execution_count":143},{"cell_type":"markdown","source":"### **Esercizio: Crea una funzione che esegua una pipeline di Regressione Lineare**\n\nLa funzione deve richiedere un parametro `hyperparams` per gestire i diversi casi. \n\n`hyperparams` deve essere un dizionario contenente diverse chiavi, in base al valore di queste chiavi devono essere eseguiti (oppure no) diversi pezzi di codice. \n\nIn questo esercizio la chiave da utilizzare sarà `hyperparams['data_standardize']`. Se il valore di questa chiave sarà **True** allora eseguire la standardizzazione con `scikit-learn`, se invece è **False** non verrà eseguita alcuna standardizzazione.\n\n**Step 1:** Controllare se eseguire o no la standardizzazione.\n\n* **Step 1.1:** Scrivere il codice per eseguire la standardizzazione.\n\n**Step 2:** Utilizza `np.c_` per concatenare una colonna di uno alle matrici delle caratteristiche.\n\n**Step 3:** Applichiamo la formula matematica della regressione lineare.\n\n**Step 4:** Calcolo MAE utilizzando la formula (NON con `scikit-learn`).\n\nLa funzione deve ritornare i valori della MAE.","metadata":{}},{"cell_type":"markdown","source":"Dopo aver testato i risultati con `hyperparams['data_standardize']` = **True**, provare anche i risultati ottenuti se `hyperparams['data_standardize']` = **False**.","metadata":{}},{"cell_type":"code","source":"# svolgimento...\n\ndef pipeline(X_train, y_train, X_val, y_val, hyperparams):\n\n    X_train = np.array(X_train, dtype=float)\n    y_train = np.array(y_train, dtype=float)\n    X_val = np.array(X_val, dtype=float)\n    y_val = np.array(y_val, dtype=float)\n    \n    # Step 1 - Controllo se è richiesta la standardizzazione dei dati\n    if hyperparams['data_standardize']:\n        \n        # Step 1.1 - Scrivere il codice per standardizzare i dati \n        X_train_norm=ss.fit_transform(X_train)\n        X_val_norm=ss.transform(X_val)\n    \n    # Step 2 - Concatenare una colonna di uno alla matrice delle features\n        vettore_di_uni_tr = np.ones((X_train_norm.shape[0], 1))\n        X_train_cost = np.c_[vettore_di_uni_tr,X_train_norm, ]\n\n        vettore_di_uni_val = np.ones((X_val_norm.shape[0], 1))\n        X_val_cost = np.c_[vettore_di_uni_val,X_val_norm]\n    # Step 3 - Applicare formula della regressione lineare e calcolare predizioni\n        parametri=np.linalg.inv(X_train_cost.T@X_train_cost)@X_train_cost.T@y_train\n        \n        y_predetti_train=X_train_cost@parametri\n\n        y_predetti_val=X_val_cost@parametri\n       \n\n        \n        \n\n    # Step 4 - Calcolare MAE \n        MAE=np.mean(np.abs(y_train - y_predetti_train))\n        print(\"MAE train\")\n        print(MAE)\n        MAE=np.mean(np.abs(y_val - y_predetti_val))\n        print(\"MAE val\")\n        print(MAE)","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.877211Z","iopub.execute_input":"2025-04-01T08:48:08.877499Z","iopub.status.idle":"2025-04-01T08:48:08.902598Z","shell.execute_reply.started":"2025-04-01T08:48:08.877476Z","shell.execute_reply":"2025-04-01T08:48:08.901568Z"},"trusted":true},"outputs":[],"execution_count":144},{"cell_type":"code","source":"hyperparams = {'data_standardize': True}\n\ntrain_fraction = 0.8\nvalidation_fraction = 0.2\n\nnum_train = int(train_fraction * X.shape[0])\n\nX_train = X[:num_train]\ny_train = y[:num_train]\n\nX_validation = X[num_train:]\ny_validation = y[num_train:]\n\n# Chiamare la funzione pipeline e stampare i risultati della MAE\n\n# svolgimento...\npipeline(X_train, y_train, X_validation, y_validation, hyperparams)","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.939272Z","iopub.execute_input":"2025-04-01T08:48:08.939655Z","iopub.status.idle":"2025-04-01T08:48:08.952322Z","shell.execute_reply.started":"2025-04-01T08:48:08.939624Z","shell.execute_reply":"2025-04-01T08:48:08.951132Z"},"trusted":true},"outputs":[{"name":"stdout","text":"MAE train\n3.3692123106941234\nMAE val\n3.023751047336023\n","output_type":"stream"}],"execution_count":145},{"cell_type":"markdown","source":"### **Esercizio: Implementare alla funzione `pipeline` la possibilità di usare PCA**\n\nModifichiamo la funzione `pipeline` in modo da gestire anche la possibilità di effettuare la PCA. Dunque aggiungiamo al dizionario `hyperparams` la chiave `use_pca`. \n\nSe `hyperparams['use_pca']` = **True** verrà eseguita la PCA. \n\nSe `hyperparams['use_pca']` = **False** non verrà eseguita la PCA.\n\nLa gestione della standardizzazione deve essere mantenuta come prima.","metadata":{}},{"cell_type":"code","source":"# svolgimento...\nfrom sklearn.decomposition import PCA\n\ndef pipeline(X_train, y_train, X_val, y_val, hyperparams):\n\n    X_train = np.array(X_train, dtype=float)\n    y_train = np.array(y_train, dtype=float)\n    X_val = np.array(X_val, dtype=float)\n    y_val = np.array(y_val, dtype=float)\n\n    # Step 1 - Controllo se è richista la PCA\n    if hyperparams['use_pca']:\n        \n        # Step 1.1 - Scrivere il codice per applicare PCA\n        s=StandardScaler()\n        s.fit_transform(X_train)\n        n_components = 3\n        p=PCA(n_components)\n        proi=p.fit_transform(X_train)\n        \n    \n    # Step 2 - Controllo se è richiesta la standardizzazione dei dati\n    if hyperparams['data_standardize']:\n    #step 1\n        X_train_norm=ss.fit_transform(X_train)\n        X_val_norm=ss.transform(X_val)\n    # Step 2 - Concatenare una colonna di uno alla matrice delle features\n        vettore_di_uni_tr = np.ones((X_train_norm.shape[0], 1))\n        X_train_cost = np.c_[vettore_di_uni_tr,X_train_norm, ]\n        vettore_di_uni_val = np.ones((X_val_norm.shape[0], 1))\n        X_val_cost = np.c_[vettore_di_uni_val,X_val_norm]\n    # Step 3 - Applicare formula della regressione lineare e calcolare predizioni\n        parametri=np.linalg.inv(X_train_cost.T@X_train_cost)@X_train_cost.T@y_train\n        y_predetti_train=X_train_cost@parametri\n        y_predetti_val=X_val_cost@parametri\n    # Step 4 - Calcolare MAE \n        MAE=np.mean(np.abs(y_train - y_predetti_train))\n        print(\"MAE train\")\n        print(MAE)\n        MAE=np.mean(np.abs(y_val - y_predetti_val))\n        print(\"MAE val\")\n        print(MAE)","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:48:08.992648Z","iopub.execute_input":"2025-04-01T08:48:08.993020Z","iopub.status.idle":"2025-04-01T08:48:09.092118Z","shell.execute_reply.started":"2025-04-01T08:48:08.992973Z","shell.execute_reply":"2025-04-01T08:48:09.090897Z"},"trusted":true},"outputs":[],"execution_count":146},{"cell_type":"code","source":"hyperparams = {'data_standardize': True, 'use_pca': True}\ntrain_fraction = 0.8\nvalidation_fraction = 0.2\n\nnum_train = int(train_fraction * X.shape[0])\n\nX_train = X[:num_train]\ny_train = y[:num_train]\n\nX_validation = X[num_train:]\ny_validation = y[num_train:]\n\n# Chiamare la funzione pipeline e stampare i risultati della MAE al variare dell' utilizzo della PCA.\n\n# svolgimento...\npipeline(X_train, y_train, X_validation, y_validation, hyperparams)","metadata":{"execution":{"iopub.status.busy":"2025-04-01T08:56:57.253278Z","iopub.execute_input":"2025-04-01T08:56:57.253722Z","iopub.status.idle":"2025-04-01T08:56:57.278925Z","shell.execute_reply.started":"2025-04-01T08:56:57.253691Z","shell.execute_reply":"2025-04-01T08:56:57.277676Z"},"trusted":true},"outputs":[{"name":"stdout","text":"MAE train\n3.3692123106941234\nMAE val\n3.023751047336023\n","output_type":"stream"}],"execution_count":148}]}